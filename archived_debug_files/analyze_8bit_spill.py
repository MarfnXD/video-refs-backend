"""
Script para executar an√°lise multimodal completa do bookmark "8-Bit Spill"
"""
import os
import asyncio
from dotenv import load_dotenv
from supabase import create_client, Client
import logging

# Carrega vari√°veis de ambiente do .env
load_dotenv()

from services.video_analysis_service import video_analysis_service
from services.claude_service import claude_service

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configura√ß√µes
SUPABASE_URL = os.getenv("SUPABASE_URL", "https://twwpcnyqpwznzarguzit.supabase.co")
SUPABASE_SERVICE_ROLE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_KEY")

if not SUPABASE_SERVICE_ROLE_KEY:
    raise Exception("SUPABASE_KEY n√£o configurada")

# Cliente Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)

async def analyze_8bit_spill():
    """Executa an√°lise multimodal completa do 8-Bit Spill"""

    bookmark_id = "419aa662-420c-4564-81c5-b2138def6b73"
    url = "https://www.instagram.com/reel/DPFquQ9DKc-/?igsh=eHhhYXhxbmdkdTBv"

    logger.info(f"\n{'='*80}")
    logger.info(f"üé¨ AN√ÅLISE MULTIMODAL COMPLETA: 8-Bit Spill")
    logger.info(f"{'='*80}")

    # 1. Busca dados atuais
    logger.info(f"\nüìä ETAPA 1: BUSCANDO DADOS ATUAIS")
    response = supabase.table('bookmarks') \
        .select('*') \
        .eq('id', bookmark_id) \
        .execute()

    if not response.data:
        logger.error(f"‚ùå Bookmark n√£o encontrado!")
        return

    bookmark = response.data[0]
    metadata = bookmark.get('metadata', {}) or {}

    logger.info(f"‚úÖ Bookmark encontrado: {bookmark.get('title')}")
    logger.info(f"   Views: {metadata.get('views', 0)}")
    logger.info(f"   Likes: {metadata.get('likes', 0)}")
    logger.info(f"   Coment√°rios: {len(metadata.get('top_comments', []))}")

    # Verifica se j√° tem cloud_video_url
    cloud_video_url = bookmark.get('cloud_video_url')
    local_video_path = bookmark.get('local_video_path')

    logger.info(f"\nüìπ Status do v√≠deo:")
    logger.info(f"   Cloud URL: {'‚úÖ Sim' if cloud_video_url else '‚ùå N√£o'}")
    logger.info(f"   Local Path: {'‚úÖ Sim' if local_video_path else '‚ùå N√£o'}")

    # 2. An√°lise multimodal
    logger.info(f"\n{'='*80}")
    logger.info(f"üé§üñºÔ∏è ETAPA 2: AN√ÅLISE MULTIMODAL (Whisper + GPT-4 Vision)")
    logger.info(f"{'='*80}")

    video_path_for_analysis = None

    # Prioriza v√≠deo local (an√°lise precisa de arquivo no disco)
    if local_video_path:
        # O v√≠deo foi baixado no CELULAR, mas esse script roda no BACKEND
        # Precisamos que o v√≠deo esteja no servidor ou baixar temporariamente
        logger.warning(f"‚ö†Ô∏è V√≠deo existe no celular, mas n√£o no servidor backend")
        logger.info(f"   Local path (celular): {local_video_path}")
        logger.info(f"   Cloud URL: {cloud_video_url[:80] if cloud_video_url else 'N/A'}...")

        if cloud_video_url:
            logger.info(f"‚úÖ Baixando v√≠deo temporariamente da cloud...")
            import tempfile
            import requests

            try:
                # Baixa v√≠deo para arquivo tempor√°rio
                response = requests.get(cloud_video_url, stream=True, timeout=60)
                response.raise_for_status()

                # Cria arquivo tempor√°rio com extens√£o .mp4
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')

                # Baixa em chunks
                for chunk in response.iter_content(chunk_size=8192):
                    temp_file.write(chunk)

                temp_file.close()
                video_path_for_analysis = temp_file.name

                size_mb = os.path.getsize(video_path_for_analysis) / (1024 * 1024)
                logger.info(f"‚úÖ V√≠deo baixado: {video_path_for_analysis} ({size_mb:.2f} MB)")

            except Exception as e:
                logger.error(f"‚ùå Erro ao baixar v√≠deo da cloud: {str(e)}")
                video_path_for_analysis = None
    else:
        logger.warning(f"‚ö†Ô∏è V√≠deo n√£o dispon√≠vel localmente")
        logger.info(f"   Para an√°lise completa, √© necess√°rio ter o v√≠deo baixado")
        logger.info(f"   Continuando com an√°lise apenas dos metadados...")

    video_transcript = None
    visual_analysis = None
    transcript_language = None

    if video_path_for_analysis:
        try:
            logger.info(f"üé¨ Iniciando an√°lise do v√≠deo...")

            # Chama servi√ßo de an√°lise multimodal
            analysis_result = await video_analysis_service.analyze_video(
                video_path=video_path_for_analysis
            )

            if analysis_result:
                video_transcript = analysis_result.get('transcript')
                visual_analysis = analysis_result.get('visual_analysis')
                transcript_language = analysis_result.get('language')

                logger.info(f"\n‚úÖ AN√ÅLISE MULTIMODAL CONCLU√çDA:")
                logger.info(f"   üé§ Transcri√ß√£o: {'‚úÖ Sim' if video_transcript else '‚ùå N√£o'} ({len(video_transcript) if video_transcript else 0} chars)")
                logger.info(f"   üñºÔ∏è An√°lise Visual: {'‚úÖ Sim' if visual_analysis else '‚ùå N√£o'} ({len(visual_analysis) if visual_analysis else 0} chars)")
                logger.info(f"   üåê Idioma: {transcript_language or 'N/A'}")

                if video_transcript:
                    logger.info(f"\nüìù TRANSCRI√á√ÉO:")
                    logger.info(f"   {video_transcript[:200]}...")

                if visual_analysis:
                    logger.info(f"\nüñºÔ∏è AN√ÅLISE VISUAL:")
                    logger.info(f"   {visual_analysis[:200]}...")

                # Salva no Supabase
                update_data = {
                    'video_transcript': video_transcript,
                    'visual_analysis': visual_analysis,
                    'transcript_language': transcript_language,
                    'analyzed_at': 'now()'
                }
                supabase.table('bookmarks').update(update_data).eq('id', bookmark_id).execute()
                logger.info(f"\nüíæ An√°lise multimodal salva no Supabase!")

            else:
                logger.error(f"‚ùå An√°lise multimodal falhou (sem resultado)")

        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise multimodal: {str(e)}")
            import traceback
            traceback.print_exc()
    else:
        logger.info(f"‚ö†Ô∏è Pulando an√°lise multimodal (v√≠deo n√£o dispon√≠vel)")

    # 3. Reprocessa com IA incluindo transcri√ß√£o e an√°lise visual
    logger.info(f"\n{'='*80}")
    logger.info(f"ü§ñ ETAPA 3: REPROCESSAMENTO COM IA (com transcri√ß√£o + visual)")
    logger.info(f"{'='*80}")

    try:
        result = await claude_service.process_metadata_auto(
            title=bookmark.get('title'),
            description=metadata.get('description', ''),
            hashtags=metadata.get('hashtags', []),
            top_comments=metadata.get('top_comments', []),
            video_transcript=video_transcript or bookmark.get('video_transcript', ''),
            visual_analysis=visual_analysis or bookmark.get('visual_analysis', ''),
            user_context=bookmark.get('user_context_raw', '')
        )

        if result:
            # Salva resultados da IA (INCLUINDO filtered_comments!)
            update_data = {
                'auto_description': result.get('auto_description'),
                'auto_tags': result.get('auto_tags'),
                'auto_categories': result.get('auto_categories'),
                'relevance_score': result.get('relevance_score'),
                'ai_processed': True
            }

            # ‚≠ê FILTERED_COMMENTS (TOP 5)
            if 'filtered_comments' in result:
                update_data['filtered_comments'] = result['filtered_comments']
                logger.info(f"\nüí¨ TOP 5 COMENT√ÅRIOS FILTRADOS:")
                for i, comment in enumerate(result['filtered_comments'][:5], 1):
                    logger.info(f"   {i}. {comment.get('text', '')[:80]}...")

            supabase.table('bookmarks').update(update_data).eq('id', bookmark_id).execute()

            logger.info(f"\n‚úÖ SUCESSO! DADOS COMPLETOS SALVOS:")
            logger.info(f"   üìù auto_description: {result.get('auto_description')[:100]}...")
            logger.info(f"   üè∑Ô∏è auto_tags: {result.get('auto_tags')}")
            logger.info(f"   üìÅ auto_categories: {result.get('auto_categories')}")
            logger.info(f"   ‚≠ê relevance_score: {result.get('relevance_score')}")
            logger.info(f"   üí¨ filtered_comments: {len(result.get('filtered_comments', []))} coment√°rios")
        else:
            logger.error(f"‚ùå Processamento de IA falhou")

    except Exception as e:
        logger.error(f"‚ùå Erro no reprocessamento: {str(e)}")
        import traceback
        traceback.print_exc()

    logger.info(f"\n{'='*80}")
    logger.info(f"‚úÖ AN√ÅLISE COMPLETA CONCLU√çDA!")
    logger.info(f"{'='*80}")
    logger.info(f"\nüì± No app, fa√ßa pull-to-refresh para ver os novos dados:")
    logger.info(f"   - üé§ Transcri√ß√£o do √°udio")
    logger.info(f"   - üñºÔ∏è An√°lise visual dos frames")
    logger.info(f"   - üí¨ Top 5 coment√°rios filtrados")

    # Cleanup: remove arquivo tempor√°rio
    if video_path_for_analysis and video_path_for_analysis.startswith('/tmp'):
        try:
            os.unlink(video_path_for_analysis)
            logger.info(f"\nüßπ Arquivo tempor√°rio removido: {video_path_for_analysis}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel remover arquivo tempor√°rio: {e}")

if __name__ == "__main__":
    asyncio.run(analyze_8bit_spill())
