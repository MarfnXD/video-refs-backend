from dotenv import load_dotenv
import os

# IMPORTANTE: Carregar .env ANTES de importar os servi√ßos
load_dotenv()

from fastapi import FastAPI, HTTPException, File, UploadFile, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
import tempfile
import logging
from models import VideoMetadata, Platform
from services.apify_service import ApifyService
from services.whisper_service import whisper_service
from services.claude_service import claude_service
from services.chat_service import chat_with_ai, find_similar_bookmarks
from services.transcoding_service import TranscodingService
from services.thumbnail_service import ThumbnailService
from services.video_analysis_service import video_analysis_service
from supabase import create_client, Client

# Background processor (FastAPI Background Tasks - substitui Celery)
from background_processor import process_bookmark_background

# Configurar logging
logging.basicConfig(level=logging.DEBUG)  # DEBUG tempor√°rio para diagnosticar fluxo Gemini‚ÜíClaude
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Video Refs Metadata API",
    description="API para extra√ß√£o de metadados de v√≠deos do YouTube, TikTok e Instagram",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

apify_service = ApifyService()
transcoding_service = TranscodingService()

# Inicializar Supabase client para ThumbnailService
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase_client: Client = create_client(supabase_url, supabase_key) if supabase_url and supabase_key else None
thumbnail_service = ThumbnailService(supabase_client) if supabase_client else None


class ExtractRequest(BaseModel):
    url: str
    user_id: Optional[str] = None  # Para upload de thumbnail na cloud
    bookmark_id: Optional[str] = None  # Para upload de thumbnail na cloud


class ExtractResponse(BaseModel):
    success: bool
    metadata: VideoMetadata = None  # Renomeado de 'data' para 'metadata' (compatibilidade com Flutter)
    error: str = None


class ProcessContextResponse(BaseModel):
    success: bool
    transcribed_text: Optional[str] = None
    context_processed: Optional[str] = None
    tags: Optional[List[str]] = None
    suggested_categories: Optional[List[str]] = None
    suggested_projects: Optional[List[str]] = None
    search_keywords: Optional[List[str]] = None
    confidence: Optional[str] = None
    error: Optional[str] = None


class ProcessMetadataAutoRequest(BaseModel):
    title: str
    description: Optional[str] = None
    hashtags: Optional[List[str]] = None
    top_comments: Optional[List[dict]] = None
    local_video_path: Optional[str] = None  # Caminho do v√≠deo local para an√°lise (transcri√ß√£o + visual)
    cloud_video_url: Optional[str] = None  # URL do v√≠deo na cloud (Supabase) - ser√° baixado temporariamente
    user_context: Optional[str] = None  # Contexto manual do usu√°rio (peso m√°ximo na an√°lise!)


class ProcessMetadataAutoResponse(BaseModel):
    success: bool
    auto_description: Optional[str] = None
    auto_tags: Optional[List[str]] = None
    auto_categories: Optional[List[str]] = None
    confidence: Optional[str] = None
    relevance_score: Optional[float] = None
    video_transcript: Optional[str] = None  # Transcri√ß√£o do √°udio (Whisper)
    visual_analysis: Optional[str] = None   # An√°lise visual (GPT-4 Vision)
    transcript_language: Optional[str] = None  # Idioma detectado
    video_transcript_pt: Optional[str] = None  # Tradu√ß√£o PT da transcri√ß√£o
    visual_analysis_pt: Optional[str] = None  # Tradu√ß√£o PT da an√°lise visual
    filtered_comments: Optional[List[dict]] = None  # 50 melhores coment√°rios filtrados
    error: Optional[str] = None


class ExtractVideoUrlRequest(BaseModel):
    url: str
    quality: Optional[str] = "480p"  # 360p, 480p, 720p
    transcode: Optional[bool] = False  # Se True, transcodifica para H.264 Baseline (lento mas compat√≠vel)


class ExtractVideoUrlResponse(BaseModel):
    success: bool
    download_url: Optional[str] = None
    expires_in_hours: Optional[int] = None
    file_size_mb: Optional[float] = None
    quality: Optional[str] = None
    platform: Optional[str] = None
    error: Optional[str] = None


@app.get("/")
async def root():
    return {"message": "Video Refs Metadata API", "version": "1.0.0"}


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


@app.post("/api/extract-metadata", response_model=ExtractResponse)
async def extract_metadata(request: ExtractRequest):
    """
    Extrai metadados de v√≠deos do YouTube, TikTok e Instagram.

    Par√¢metros:
    - url: URL do v√≠deo para extrair metadados
    - user_id: ID do usu√°rio (opcional, para upload de thumbnail permanente)
    - bookmark_id: ID do bookmark (opcional, para upload de thumbnail permanente)

    Retorna:
    - VideoMetadata com todos os dados extra√≠dos
    - Se user_id e bookmark_id forem fornecidos, faz upload da thumbnail para Supabase Storage
    - Cache autom√°tico por 7 dias
    """
    try:
        if not request.url:
            raise HTTPException(status_code=400, detail="URL √© obrigat√≥ria")

        metadata = await apify_service.extract_metadata(request.url)

        # Se user_id e bookmark_id foram fornecidos E thumbnail_service est√° dispon√≠vel,
        # faz upload da thumbnail para Supabase Storage
        if (request.user_id and request.bookmark_id and
            thumbnail_service and metadata.thumbnail_url):

            logger.info(f"üì∏ Fazendo upload de thumbnail para bookmark {request.bookmark_id}")

            cloud_thumbnail_url = await thumbnail_service.upload_thumbnail(
                thumbnail_url=metadata.thumbnail_url,
                user_id=request.user_id,
                bookmark_id=request.bookmark_id
            )

            if cloud_thumbnail_url:
                metadata.cloud_thumbnail_url = cloud_thumbnail_url
                logger.info(f"‚úÖ Thumbnail permanente criada: {cloud_thumbnail_url[:80]}...")
            else:
                logger.warning("‚ö†Ô∏è Falha ao fazer upload de thumbnail, usando URL original")

        return ExtractResponse(
            success=True,
            metadata=metadata  # Campo renomeado para compatibilidade com Flutter
        )

    except ValueError as e:
        return ExtractResponse(
            success=False,
            error=str(e)
        )

    except Exception as e:
        return ExtractResponse(
            success=False,
            error=f"Erro interno: {str(e)}"
        )


@app.post("/api/process-context", response_model=ProcessContextResponse)
async def process_context(
    url: str = Form(...),
    text_context: Optional[str] = Form(None),
    audio_file: Optional[UploadFile] = File(None),
    video_title: Optional[str] = Form(None),
    platform: Optional[str] = Form(None),
    author: Optional[str] = Form(None),
    user_categories: Optional[str] = Form(None),  # JSON string de array
    user_projects: Optional[str] = Form(None)  # JSON string de array
):
    """
    Processa contexto do usu√°rio (texto ou √°udio) com IA.

    Aceita:
    - text_context: Texto digitado pelo usu√°rio (opcional)
    - audio_file: Arquivo de √°udio para transcrever (opcional)
    - url: URL do v√≠deo
    - video_title, platform, author: Metadados do v√≠deo (opcional)
    - user_categories, user_projects: Listas existentes do usu√°rio (JSON strings)

    Retorna:
    - Contexto processado, tags, categorias e projetos sugeridos
    """
    try:
        import json

        # Parse user categories e projects
        categories_list = json.loads(user_categories) if user_categories else []
        projects_list = json.loads(user_projects) if user_projects else []

        context_text = text_context
        transcription = None

        # Se tem √°udio, transcrever primeiro
        if audio_file:
            logger.info(f"üé§ Recebido √°udio: {audio_file.filename}")

            if not whisper_service.is_available():
                return ProcessContextResponse(
                    success=False,
                    error="Whisper API n√£o configurada (OPENAI_API_KEY faltando)"
                )

            # Salvar arquivo tempor√°rio
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(audio_file.filename)[1]) as tmp_file:
                content = await audio_file.read()
                tmp_file.write(content)
                tmp_path = tmp_file.name

            try:
                # Transcrever
                transcription = await whisper_service.transcribe_audio(tmp_path)
                if not transcription:
                    return ProcessContextResponse(
                        success=False,
                        error="Falha ao transcrever √°udio"
                    )

                context_text = transcription
                logger.info(f"‚úÖ Transcri√ß√£o: {transcription[:100]}...")

            finally:
                # Limpar arquivo tempor√°rio
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)

        # Se n√£o tem contexto (nem texto nem √°udio), retornar erro
        if not context_text:
            return ProcessContextResponse(
                success=False,
                error="Necess√°rio fornecer text_context ou audio_file"
            )

        # Processar contexto com Claude
        if not claude_service.is_available():
            logger.warning("Claude API n√£o configurada, retornando s√≥ transcri√ß√£o")
            return ProcessContextResponse(
                success=True,
                transcribed_text=transcription,
                context_processed=context_text,
                tags=[],
                suggested_categories=[],
                suggested_projects=[],
                search_keywords=[],
                confidence="low"
            )

        # Processar com Claude
        logger.info("üß† Processando contexto com Claude...")
        result = await claude_service.process_context(
            user_context_raw=context_text,
            video_title=video_title or "",
            platform=platform or "",
            author=author or "",
            user_categories=categories_list,
            user_projects=projects_list
        )

        if not result:
            logger.warning("Claude n√£o retornou resultado, usando fallback")
            return ProcessContextResponse(
                success=True,
                transcribed_text=transcription,
                context_processed=context_text,
                tags=[],
                suggested_categories=[],
                suggested_projects=[],
                search_keywords=[],
                confidence="low"
            )

        # Retornar sucesso com resultado processado
        return ProcessContextResponse(
            success=True,
            transcribed_text=transcription,
            context_processed=result.get("context_processed"),
            tags=result.get("tags", []),
            suggested_categories=result.get("suggested_categories", []),
            suggested_projects=result.get("suggested_projects", []),
            search_keywords=result.get("search_keywords", []),
            confidence=result.get("confidence", "medium")
        )

    except json.JSONDecodeError:
        return ProcessContextResponse(
            success=False,
            error="user_categories ou user_projects n√£o s√£o JSON v√°lidos"
        )
    except Exception as e:
        logger.error(f"‚ùå Erro em process_context: {str(e)}")
        return ProcessContextResponse(
            success=False,
            error=f"Erro interno: {str(e)}"
        )


@app.post("/api/process-metadata-auto", response_model=ProcessMetadataAutoResponse)
async def process_metadata_auto(request: ProcessMetadataAutoRequest):
    """
    Processa metadados do v√≠deo automaticamente (sem contexto do usu√°rio).

    Analisa t√≠tulo, descri√ß√£o, hashtags e coment√°rios com Claude para gerar:
    - auto_description: Resumo autom√°tico do v√≠deo
    - auto_tags: Tags extra√≠das dos metadados
    - auto_categories: Categorias sugeridas

    Se local_video_path for fornecido, tamb√©m analisa o v√≠deo:
    - Transcri√ß√£o de √°udio (Whisper API)
    - An√°lise visual de frames (GPT-4 Vision)

    Usado quando usu√°rio pula a captura de contexto.
    """
    try:
        if not request.title or not request.title.strip():
            return ProcessMetadataAutoResponse(
                success=False,
                error="T√≠tulo √© obrigat√≥rio"
            )

        # Verificar se Claude est√° dispon√≠vel
        if not claude_service.is_available():
            logger.warning("Claude API n√£o configurada, pulando processamento autom√°tico")
            return ProcessMetadataAutoResponse(
                success=False,
                error="Claude API n√£o configurada"
            )

        # Analisar v√≠deo se caminho foi fornecido
        video_transcript = ""
        visual_analysis = ""
        transcript_language = ""
        video_transcript_pt = None
        visual_analysis_pt = None
        temp_video_file = None

        # An√°lise multimodal (Whisper + GPT-4 Vision)
        video_path_for_analysis = None
        if request.local_video_path:
            video_path_for_analysis = request.local_video_path
        elif request.cloud_video_url:
            # Baixa temporariamente da cloud
            logger.info(f"‚òÅÔ∏è Baixando v√≠deo temporariamente da cloud: {request.cloud_video_url[:80]}...")
            try:
                import httpx
                import tempfile

                async with httpx.AsyncClient(timeout=180.0) as client:
                    response = await client.get(request.cloud_video_url)
                    response.raise_for_status()
                    video_data = response.content

                temp_video_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                temp_video_file.write(video_data)
                temp_video_file.close()

                video_path_for_analysis = temp_video_file.name
                size_mb = len(video_data) / (1024 * 1024)
                logger.info(f"‚úÖ V√≠deo baixado temporariamente: {size_mb:.2f} MB")
            except Exception as e:
                logger.error(f"‚ùå Erro ao baixar v√≠deo da cloud: {str(e)}")
                video_path_for_analysis = None

        if video_path_for_analysis and video_analysis_service.is_available():
            logger.info(f"üé¨ Analisando v√≠deo: {video_path_for_analysis}")
            video_analysis = await video_analysis_service.analyze_video(video_path_for_analysis)

            if video_analysis:
                video_transcript = video_analysis.get("transcript", "")
                visual_analysis = video_analysis.get("visual_analysis", "")
                transcript_language = video_analysis.get("language", "")
                video_transcript_pt = video_analysis.get("transcript_pt")
                visual_analysis_pt = video_analysis.get("visual_analysis_pt")
                logger.info(f"‚úÖ An√°lise de v√≠deo conclu√≠da - Transcript: {len(video_transcript)} chars, Visual: {len(visual_analysis)} chars")
                if video_transcript_pt:
                    logger.info(f"üåê Tradu√ß√£o PT (Transcri√ß√£o): {len(video_transcript_pt)} chars")
                if visual_analysis_pt:
                    logger.info(f"üåê Tradu√ß√£o PT (Visual): {len(visual_analysis_pt)} chars")
            else:
                logger.warning("‚ö†Ô∏è An√°lise de v√≠deo falhou, continuando sem transcri√ß√£o/visual")

            # Limpa arquivo tempor√°rio
            if temp_video_file and os.path.exists(temp_video_file.name):
                try:
                    os.unlink(temp_video_file.name)
                    logger.info(f"üßπ Arquivo tempor√°rio removido")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel remover arquivo tempor√°rio: {e}")

        # Processar metadados com Claude (com transcript + visual + user_context)
        logger.info("ü§ñ Processando metadados automaticamente...")
        result = await claude_service.process_metadata_auto(
            title=request.title,
            description=request.description or "",
            hashtags=request.hashtags or [],
            top_comments=request.top_comments or [],
            video_transcript=video_transcript,
            visual_analysis=visual_analysis,
            user_context=request.user_context or ""  # ‚≠ê PRIORIDADE M√ÅXIMA (40% de peso)
        )

        if not result:
            logger.warning("Claude n√£o retornou resultado para processamento autom√°tico")
            return ProcessMetadataAutoResponse(
                success=False,
                error="Falha ao processar metadados"
            )

        # Retornar sucesso com resultado processado
        return ProcessMetadataAutoResponse(
            success=True,
            auto_description=result.get("auto_description"),
            auto_tags=result.get("auto_tags", []),
            auto_categories=result.get("auto_categories", []),
            confidence=result.get("confidence", "medium"),
            relevance_score=result.get("relevance_score", 0.5),
            video_transcript=video_transcript if video_transcript else None,
            visual_analysis=visual_analysis if visual_analysis else None,
            transcript_language=transcript_language if transcript_language else None,
            video_transcript_pt=video_transcript_pt,
            visual_analysis_pt=visual_analysis_pt,
            filtered_comments=result.get("filtered_comments", [])
        )

    except Exception as e:
        logger.error(f"‚ùå Erro em process_metadata_auto: {str(e)}")
        return ProcessMetadataAutoResponse(
            success=False,
            error=f"Erro interno: {str(e)}"
        )


# ============================================================
# CHAT IA - Busca Sem√¢ntica Conversacional
# ============================================================

class ChatMessage(BaseModel):
    role: str  # "user" ou "assistant"
    content: str


class ChatRequest(BaseModel):
    message: str
    conversation_history: Optional[List[ChatMessage]] = None
    max_results: Optional[int] = 10


class ChatResponse(BaseModel):
    success: bool
    message: str = None
    bookmarks: List[dict] = []
    total_found: int = 0
    error: str = None


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Endpoint de chat conversacional com IA.

    Usa busca sem√¢ntica (embeddings) + Claude API para responder
    perguntas sobre bookmarks de forma natural e contextual.

    Exemplos de uso:
    - "Preciso de v√≠deos com transi√ß√µes cinematogr√°ficas escuras"
    - "Mostre refs de campanhas de Natal urbano"
    - "Quero ver efeitos de √°gua ou l√≠quidos"
    """
    try:
        logger.info(f"üí¨ Chat request: '{request.message}'")

        # Converte hist√≥rico de conversa para formato do servi√ßo
        history = None
        if request.conversation_history:
            history = [
                {"role": msg.role, "content": msg.content}
                for msg in request.conversation_history
            ]

        # Chama servi√ßo de chat
        result = await chat_with_ai(
            user_message=request.message,
            conversation_history=history,
            max_bookmarks=request.max_results or 10
        )

        return ChatResponse(
            success=True,
            message=result["message"],
            bookmarks=result["bookmarks"],
            total_found=result["total_found"]
        )

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/chat: {str(e)}")
        return ChatResponse(
            success=False,
            error=f"Erro ao processar chat: {str(e)}"
        )


@app.post("/api/transcribe-audio")
async def transcribe_audio(audio_file: UploadFile = File(...)):
    """
    Endpoint simples para transcrever √°udio usando Whisper API.

    Usado no chat para converter mensagens de voz em texto.
    """
    try:
        logger.info(f"üé§ Transcrevendo √°udio: {audio_file.filename}")

        # Salva arquivo tempor√°rio
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix=".m4a") as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_path = temp_file.name

        # Transcreve com Whisper
        from services.whisper_service import WhisperService
        whisper = WhisperService()
        transcription = await whisper.transcribe_audio(temp_path, language="pt")

        # Remove arquivo tempor√°rio
        import os
        os.remove(temp_path)

        if transcription:
            logger.info(f"‚úÖ Transcri√ß√£o: {transcription[:100]}...")
            return {"success": True, "transcription": transcription}
        else:
            logger.error("‚ùå Falha na transcri√ß√£o")
            return {"success": False, "error": "Falha ao transcrever √°udio"}

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/transcribe-audio: {str(e)}")
        return {"success": False, "error": f"Erro ao transcrever: {str(e)}"}


# ============================================================
# AN√ÅLISE MULTIMODAL DE V√çDEO (Whisper + GPT-4 Vision)
# ============================================================

class AnalyzeVideoRequest(BaseModel):
    cloud_video_url: str


class AnalyzeVideoResponse(BaseModel):
    success: bool
    video_transcript: Optional[str] = None
    visual_analysis: Optional[str] = None
    transcript_language: Optional[str] = None
    error: Optional[str] = None


@app.post("/api/analyze-video", response_model=AnalyzeVideoResponse)
async def analyze_video(request: AnalyzeVideoRequest):
    """
    Analisa v√≠deo que j√° est√° na cloud (Whisper + GPT-4 Vision).

    Fluxo:
    1. Baixa v√≠deo temporariamente da cloud URL
    2. Extrai √°udio e analisa com Whisper
    3. Extrai frames e analisa com GPT-4 Vision
    4. Retorna transcri√ß√£o, an√°lise visual e idioma
    """
    import httpx

    try:
        logger.info(f"üé¨ Analisando v√≠deo da cloud: {request.cloud_video_url[:50]}...")

        if not video_analysis_service.is_available():
            raise HTTPException(
                status_code=503,
                detail="Servi√ßo de an√°lise multimodal n√£o dispon√≠vel (OPENAI_API_KEY n√£o configurada)"
            )

        # 1. Baixar v√≠deo temporariamente
        logger.info(f"‚¨áÔ∏è  Baixando v√≠deo da cloud...")
        async with httpx.AsyncClient(timeout=180.0) as client:
            response = await client.get(request.cloud_video_url)
            response.raise_for_status()
            video_data = response.content

        # 2. Salvar em arquivo tempor√°rio
        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as temp_video:
            temp_video.write(video_data)
            temp_video_path = temp_video.name

        logger.info(f"‚úÖ V√≠deo baixado: {len(video_data) / (1024 * 1024):.2f}MB")

        # 3. Analisar v√≠deo (Whisper + GPT-4 Vision)
        logger.info(f"üé§üñºÔ∏è  Analisando com Whisper + GPT-4 Vision...")
        analysis_result = await video_analysis_service.analyze_video(temp_video_path)

        # 4. Limpar arquivo tempor√°rio
        try:
            os.unlink(temp_video_path)
        except:
            pass

        if not analysis_result:
            raise HTTPException(status_code=500, detail="An√°lise multimodal falhou")

        logger.info(f"‚úÖ An√°lise multimodal conclu√≠da!")
        logger.info(f"   - Transcri√ß√£o: {len(analysis_result.get('transcript', ''))} chars ({analysis_result.get('language', 'N/A')})")
        logger.info(f"   - An√°lise Visual: {len(analysis_result.get('visual_analysis', ''))} chars")

        return {
            "success": True,
            "video_transcript": analysis_result.get("transcript"),
            "visual_analysis": analysis_result.get("visual_analysis"),
            "transcript_language": analysis_result.get("language"),
        }

    except httpx.HTTPError as e:
        logger.error(f"‚ùå Erro ao baixar v√≠deo da cloud: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao baixar v√≠deo: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå Erro ao analisar v√≠deo: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro ao analisar v√≠deo: {str(e)}")


# ============================================================
# BUSCA POR SIMILARIDADE
# ============================================================

class FindSimilarRequest(BaseModel):
    bookmark_id: str
    user_id: str
    max_results: Optional[int] = 10


class FindSimilarResponse(BaseModel):
    success: bool
    bookmarks: List[dict] = []
    total_found: int = 0
    error: str = None


@app.post("/api/find-similar", response_model=FindSimilarResponse)
async def find_similar(request: FindSimilarRequest):
    """
    Encontra bookmarks similares a um bookmark espec√≠fico.

    Usa busca sem√¢ntica (embeddings) para encontrar v√≠deos com conte√∫do,
    contexto, tags e categorias similares.

    Exemplos de uso:
    - Encontrar v√≠deos parecidos com um que o usu√°rio gostou
    - Descobrir refs similares para expandir um projeto
    - Achar varia√ß√µes de uma t√©cnica/estilo
    """
    try:
        logger.info(f"üîó Find similar request para bookmark: {request.bookmark_id}")

        # Chama servi√ßo de busca similar
        similar_bookmarks = await find_similar_bookmarks(
            bookmark_id=request.bookmark_id,
            user_id=request.user_id,
            max_results=request.max_results or 10,
            threshold=0.5
        )

        return FindSimilarResponse(
            success=True,
            bookmarks=similar_bookmarks,
            total_found=len(similar_bookmarks)
        )

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/find-similar: {str(e)}")
        return FindSimilarResponse(
            success=False,
            error=f"Erro ao buscar similares: {str(e)}"
        )


@app.post("/api/extract-video-download-url", response_model=ExtractVideoUrlResponse)
async def extract_video_download_url(request: ExtractVideoUrlRequest):
    """
    Extrai URL direta do v√≠deo para download local no dispositivo do usu√°rio.

    IMPORTANTE:
    - Backend N√ÉO armazena o v√≠deo
    - URL √© tempor√°ria (v√°lida por 2-6 horas dependendo da plataforma)
    - Apenas facilita a extra√ß√£o da URL de download
    - Usu√°rio √© respons√°vel pelo download e armazenamento local

    Par√¢metros:
    - url: URL do v√≠deo (YouTube, Instagram, TikTok)
    - quality: Qualidade desejada (360p, 480p, 720p) - padr√£o 480p

    Retorna:
    - download_url: URL direta tempor√°ria para download
    - expires_in_hours: Tempo de validade da URL
    - file_size_mb: Tamanho estimado do arquivo
    - quality: Qualidade real do v√≠deo
    - platform: Plataforma detectada
    """
    try:
        logger.info(f"üì• Extract video download URL request: {request.url} ({request.quality})")

        # Detecta plataforma
        platform = apify_service.detect_platform(request.url)
        logger.info(f"üé¨ Plataforma detectada: {platform}")

        # Por enquanto, vamos usar apenas Instagram e TikTok
        # YouTube tem restri√ß√µes de ToS mais severas

        if platform == Platform.INSTAGRAM:
            # Instagram: Extrai URL (e opcionalmente transcodifica para compatibilidade)
            try:
                # 1. Extrair URL original do Instagram
                video_data = await apify_service.extract_video_download_url_instagram(
                    request.url,
                    request.quality
                )

                logger.info(f"‚úÖ URL de v√≠deo Instagram extra√≠da: {video_data['download_url'][:50]}...")

                # 2. Se transcode=True, transcodifica para H.264 Baseline (lento mas compat√≠vel)
                if request.transcode:
                    logger.info(f"üé¨ Transcodifica√ß√£o solicitada - garantindo compatibilidade...")
                    transcode_result = await transcoding_service.transcode_video(video_data["download_url"])

                    if not transcode_result["success"]:
                        raise ValueError(f"Falha na transcodifica√ß√£o: {transcode_result.get('error')}")

                    # Retornar URL do v√≠deo transcodificado
                    video_id = transcode_result["video_id"]
                    base_url = os.getenv("BASE_URL", "https://video-refs-backend.onrender.com")
                    transcoded_url = f"{base_url}/api/download-transcoded/{video_id}"

                    logger.info(f"‚úÖ V√≠deo transcodificado com sucesso: {video_id}")

                    return ExtractVideoUrlResponse(
                        success=True,
                        download_url=transcoded_url,
                        expires_in_hours=24,  # V√≠deo fica armazenado por 24h no backend
                        file_size_mb=transcode_result["file_size_mb"],
                        quality="baseline_h264",  # Indica que foi transcodificado
                        platform="instagram"
                    )
                else:
                    # Sem transcodifica√ß√£o - retorna URL direta (r√°pido!)
                    logger.info(f"‚ö° Retornando URL direta sem transcodifica√ß√£o (modo r√°pido)")

                    return ExtractVideoUrlResponse(
                        success=True,
                        download_url=video_data["download_url"],
                        expires_in_hours=video_data.get("expires_in_hours", 2),
                        file_size_mb=video_data.get("file_size_mb"),
                        quality=video_data.get("quality", "original"),
                        platform="instagram"
                    )

            except Exception as e:
                logger.error(f"‚ùå Erro ao processar Instagram: {str(e)}")
                return ExtractVideoUrlResponse(
                    success=False,
                    error=f"Erro ao extrair v√≠deo do Instagram: {str(e)}"
                )

        elif platform == Platform.TIKTOK:
            # TikTok: Extrai URL (e opcionalmente transcodifica para compatibilidade)
            try:
                # 1. Extrair URL original do TikTok
                video_data = await apify_service.extract_video_download_url_tiktok(
                    request.url,
                    request.quality
                )

                logger.info(f"‚úÖ URL de v√≠deo TikTok extra√≠da: {video_data['download_url'][:50]}...")

                # 2. Se transcode=True, transcodifica para H.264 Baseline (lento mas compat√≠vel)
                if request.transcode:
                    logger.info(f"üé¨ Transcodifica√ß√£o solicitada - garantindo compatibilidade...")
                    transcode_result = await transcoding_service.transcode_video(video_data["download_url"])

                    if not transcode_result["success"]:
                        raise ValueError(f"Falha na transcodifica√ß√£o: {transcode_result.get('error')}")

                    # Retornar URL do v√≠deo transcodificado
                    video_id = transcode_result["video_id"]
                    base_url = os.getenv("BASE_URL", "https://video-refs-backend.onrender.com")
                    transcoded_url = f"{base_url}/api/download-transcoded/{video_id}"

                    logger.info(f"‚úÖ V√≠deo transcodificado com sucesso: {video_id}")

                    return ExtractVideoUrlResponse(
                        success=True,
                        download_url=transcoded_url,
                        expires_in_hours=24,  # V√≠deo fica armazenado por 24h no backend
                        file_size_mb=transcode_result["file_size_mb"],
                        quality="baseline_h264",  # Indica que foi transcodificado
                        platform="tiktok"
                    )
                else:
                    # Sem transcodifica√ß√£o - retorna URL direta (r√°pido!)
                    logger.info(f"‚ö° Retornando URL direta sem transcodifica√ß√£o (modo r√°pido)")

                    return ExtractVideoUrlResponse(
                        success=True,
                        download_url=video_data["download_url"],
                        expires_in_hours=video_data.get("expires_in_hours", 6),
                        file_size_mb=video_data.get("file_size_mb"),
                        quality=video_data.get("quality", "original"),
                        platform="tiktok"
                    )

            except Exception as e:
                logger.error(f"‚ùå Erro ao processar TikTok: {str(e)}")
                return ExtractVideoUrlResponse(
                    success=False,
                    error=f"Erro ao extrair v√≠deo do TikTok: {str(e)}"
                )

        elif platform == Platform.YOUTUBE:
            # YouTube: Por enquanto n√£o suportado devido a ToS
            return ExtractVideoUrlResponse(
                success=False,
                platform="youtube",
                error="Download de v√≠deos do YouTube n√£o √© suportado devido √†s pol√≠ticas de uso. "
                      "Voc√™ pode visualizar o v√≠deo direto no YouTube atrav√©s do link."
            )

        else:
            return ExtractVideoUrlResponse(
                success=False,
                error=f"Plataforma n√£o suportada: {platform}"
            )

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/extract-video-download-url: {str(e)}")
        return ExtractVideoUrlResponse(
            success=False,
            error=f"Erro interno: {str(e)}"
        )


class TranscodeVideoRequest(BaseModel):
    source_url: str


class TranscodeVideoResponse(BaseModel):
    success: bool
    video_id: str = None
    file_size_mb: float = None
    error: str = None


@app.post("/api/transcode-video", response_model=TranscodeVideoResponse)
async def transcode_video_endpoint(request: TranscodeVideoRequest):
    """
    Transcodifica v√≠deo para H.264 Baseline Profile (compat√≠vel com Android).

    Args:
        source_url: URL do v√≠deo original

    Returns:
        video_id: ID para baixar o v√≠deo transcodificado via /api/download-transcoded/{video_id}
    """
    try:
        logger.info(f"üé¨ Iniciando transcodifica√ß√£o de: {request.source_url[:50]}...")

        result = await transcoding_service.transcode_video(request.source_url)

        if result["success"]:
            logger.info(f"‚úÖ Transcodifica√ß√£o conclu√≠da: {result['video_id']}")
            return TranscodeVideoResponse(
                success=True,
                video_id=result["video_id"],
                file_size_mb=result["file_size_mb"],
            )
        else:
            logger.error(f"‚ùå Erro na transcodifica√ß√£o: {result['error']}")
            return TranscodeVideoResponse(
                success=False,
                error=result["error"],
            )

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/transcode-video: {str(e)}")
        return TranscodeVideoResponse(
            success=False,
            error=f"Erro interno: {str(e)}",
        )


@app.get("/api/download-transcoded/{video_id}")
async def download_transcoded_video(video_id: str):
    """
    Retorna v√≠deo transcodificado para download.
    """
    try:
        from fastapi.responses import FileResponse

        file_path = transcoding_service.get_video_path(video_id)

        if not transcoding_service.video_exists(video_id):
            raise HTTPException(status_code=404, detail="V√≠deo n√£o encontrado")

        return FileResponse(
            path=file_path,
            media_type="video/mp4",
            filename=f"{video_id}.mp4",
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erro em /api/download-transcoded: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")


@app.get("/api/transcoding-stats")
async def get_transcoding_stats():
    """
    Retorna estat√≠sticas de uso de armazenamento de v√≠deos transcodificados.
    """
    try:
        stats = transcoding_service.get_storage_usage()
        return stats
    except Exception as e:
        logger.error(f"‚ùå Erro em /api/transcoding-stats: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")


class ProcessToSupabaseRequest(BaseModel):
    url: str
    user_id: str
    bookmark_id: str
    quality: str = "720p"


class ProcessToSupabaseResponse(BaseModel):
    success: bool
    cloud_url: str = None
    file_size_mb: float = None
    error: str = None


@app.post("/api/process-to-supabase", response_model=ProcessToSupabaseResponse)
async def process_video_to_supabase(request: ProcessToSupabaseRequest):
    """
    Processa v√≠deo COMPLETO e faz upload direto para Supabase Storage.

    Fluxo:
    1. Apify extrai URL do v√≠deo
    2. Backend baixa v√≠deo
    3. FFmpeg transcodifica (H.264 Baseline)
    4. Upload direto para Supabase Storage
    5. Atualiza bookmark no Supabase
    6. Retorna apenas sucesso/falha

    VANTAGEM: V√≠deo N√ÉO trafega para o PC - tudo servidor‚Üíservidor
    """
    import httpx
    from datetime import datetime

    try:
        logger.info(f"üöÄ Processando v√≠deo para Supabase: {request.url}")

        # 1. Detectar plataforma e extrair URL
        platform = apify_service.detect_platform(request.url)
        logger.info(f"üé¨ Plataforma: {platform}")

        if platform == Platform.INSTAGRAM:
            video_data = await apify_service.extract_video_download_url_instagram(request.url, request.quality)
        elif platform == Platform.TIKTOK:
            video_data = await apify_service.extract_video_download_url_tiktok(request.url, request.quality)
        else:
            raise ValueError(f"Plataforma n√£o suportada: {platform}")

        download_url = video_data["download_url"]
        thumbnail_url = video_data.get("thumbnail_url")  # Apify retorna thumbnail
        logger.info(f"‚úÖ URL extra√≠da: {download_url[:50]}...")

        # 2. Baixar e salvar thumbnail (se dispon√≠vel)
        cloud_thumbnail_url = None
        if thumbnail_url:
            try:
                logger.info(f"üì∏ Baixando thumbnail...")
                async with httpx.AsyncClient(timeout=30.0) as client:
                    thumb_response = await client.get(thumbnail_url)
                    thumb_response.raise_for_status()
                    thumbnail_data = thumb_response.content

                # Upload thumbnail para Supabase Storage
                thumbnail_storage_path = f"{request.user_id}/thumbnails/{request.bookmark_id}.jpg"

                import io
                supabase_client.storage.from_('user-videos').upload(
                    thumbnail_storage_path,
                    io.BytesIO(thumbnail_data),
                    file_options={"content-type": "image/jpeg"}
                )

                # Gerar URL assinada para thumbnail
                cloud_thumbnail_url = supabase_client.storage.from_('user-videos').create_signed_url(
                    thumbnail_storage_path,
                    expires_in=31536000  # 1 ano
                )['signedURL']

                logger.info(f"‚úÖ Thumbnail salva!")
            except Exception as thumb_error:
                logger.warning(f"‚ö†Ô∏è  Erro ao salvar thumbnail (n√£o cr√≠tico): {str(thumb_error)}")
                # N√£o falha o processo se thumbnail falhar

        # 3. Transcodificar (baixa + FFmpeg)
        logger.info(f"üé¨ Baixando e transcodificando...")
        transcode_result = await transcoding_service.transcode_video(download_url)

        if not transcode_result["success"]:
            raise ValueError(f"Falha na transcodifica√ß√£o: {transcode_result.get('error')}")

        transcoded_path = transcode_result["file_path"]
        file_size_mb = transcode_result["file_size_mb"]

        logger.info(f"‚úÖ Transcodificado: {file_size_mb:.2f}MB")

        # 3.5. An√°lise Multimodal (opcional mas recomendado)
        video_transcript = None
        visual_analysis = None
        transcript_language = None
        video_transcript_pt = None
        visual_analysis_pt = None

        if video_analysis_service.is_available():
            try:
                logger.info(f"üé§üñºÔ∏è  Analisando v√≠deo (√°udio + visual)...")
                video_analysis = await video_analysis_service.analyze_video(transcoded_path)

                if video_analysis:
                    video_transcript = video_analysis.get("transcript", "")
                    visual_analysis = video_analysis.get("visual_analysis", "")
                    transcript_language = video_analysis.get("language", "")
                    video_transcript_pt = video_analysis.get("transcript_pt")
                    visual_analysis_pt = video_analysis.get("visual_analysis_pt")

                    logger.info(f"‚úÖ An√°lise multimodal conclu√≠da!")
                    logger.info(f"   - Transcri√ß√£o: {len(video_transcript)} chars ({transcript_language})")
                    logger.info(f"   - An√°lise Visual: {len(visual_analysis)} chars")
                    if video_transcript_pt:
                        logger.info(f"   - Tradu√ß√£o PT (Transcri√ß√£o): {len(video_transcript_pt)} chars")
                    if visual_analysis_pt:
                        logger.info(f"   - Tradu√ß√£o PT (Visual): {len(visual_analysis_pt)} chars")
            except Exception as analysis_error:
                # N√£o cr√≠tico - continua mesmo se an√°lise falhar
                logger.warning(f"‚ö†Ô∏è  An√°lise multimodal falhou (n√£o cr√≠tico): {str(analysis_error)}")
        else:
            logger.info(f"‚è≠Ô∏è  An√°lise multimodal desabilitada (OPENAI_API_KEY n√£o configurada)")

        # 4. Upload direto para Supabase Storage
        logger.info(f"‚òÅÔ∏è  Fazendo upload para Supabase...")

        storage_path = f"{request.user_id}/{request.bookmark_id}.mp4"

        with open(transcoded_path, 'rb') as f:
            supabase_client.storage.from_('user-videos').upload(
                storage_path,
                f,
                file_options={"content-type": "video/mp4"}
            )

        # Gerar URL assinada
        cloud_url = supabase_client.storage.from_('user-videos').create_signed_url(
            storage_path,
            expires_in=31536000  # 1 ano
        )['signedURL']

        logger.info(f"‚úÖ Upload conclu√≠do!")

        # 4. Atualizar bookmark no Supabase
        update_data = {
            'cloud_video_url': cloud_url,
            'cloud_upload_status': 'completed',
            'cloud_uploaded_at': datetime.utcnow().isoformat(),
            'cloud_file_size_bytes': int(file_size_mb * 1024 * 1024),
            'video_quality': request.quality,
        }

        # Adiciona thumbnail URL se dispon√≠vel
        if cloud_thumbnail_url:
            update_data['cloud_thumbnail_url'] = cloud_thumbnail_url

        # Adiciona dados de an√°lise multimodal se dispon√≠veis
        if video_transcript:
            update_data['video_transcript'] = video_transcript
        if visual_analysis:
            update_data['visual_analysis'] = visual_analysis
        if transcript_language:
            update_data['transcript_language'] = transcript_language
        if video_transcript_pt:
            update_data['video_transcript_pt'] = video_transcript_pt
        if visual_analysis_pt:
            update_data['visual_analysis_pt'] = visual_analysis_pt
        if video_transcript or visual_analysis:
            update_data['analyzed_at'] = datetime.utcnow().isoformat()

        supabase_client.table('bookmarks').update(update_data).eq('id', request.bookmark_id).execute()

        logger.info(f"‚úÖ Bookmark atualizado!")

        # 5. Limpar arquivo transcodificado
        os.unlink(transcoded_path)

        return ProcessToSupabaseResponse(
            success=True,
            cloud_url=cloud_url,
            file_size_mb=file_size_mb
        )

    except Exception as e:
        logger.error(f"‚ùå Erro em /api/process-to-supabase: {str(e)}")
        return ProcessToSupabaseResponse(
            success=False,
            error=str(e)
        )


# ============================================================================
# NOVO ENDPOINT: Processamento completo em background (Celery)
# ============================================================================

class ProcessBookmarkCompleteRequest(BaseModel):
    """
    Request para processamento completo de bookmark em background
    """
    bookmark_id: str
    url: str
    user_id: str
    extract_metadata: bool = True
    analyze_video: bool = True
    process_ai: bool = True
    upload_to_cloud: bool = False
    user_context: Optional[str] = None  # Contexto do usu√°rio (peso 40% na IA)


class ProcessBookmarkCompleteResponse(BaseModel):
    """
    Response imediata com job_id
    """
    success: bool
    job_id: str = None
    bookmark_id: str = None
    estimated_time_seconds: int = None
    message: str = None
    error: str = None


@app.post("/api/process-bookmark-complete", response_model=ProcessBookmarkCompleteResponse)
async def process_bookmark_complete(
    request: ProcessBookmarkCompleteRequest,
    background_tasks: BackgroundTasks
):
    """
    **PROCESSAMENTO 100% EM BACKGROUND (FastAPI Background Tasks)**

    Phone envia requisi√ß√£o e desconecta - backend processa TUDO em background.

    **Fluxo:**
    1. Valida requisi√ß√£o
    2. Adiciona task em background (FastAPI Background Tasks)
    3. Retorna success IMEDIATAMENTE
    4. Backend processa em background:
       - Extra√ß√£o de metadados (Apify)
       - An√°lise de v√≠deo (Gemini Flash 2.5) - OPCIONAL
       - Processamento de IA (Claude)
       - Atualiza Supabase
    5. Phone sincroniza via Supabase Realtime

    **Par√¢metros:**
    - bookmark_id: UUID do bookmark (j√° criado no Supabase)
    - url: URL do v√≠deo (YouTube/Instagram/TikTok)
    - user_id: UUID do usu√°rio
    - extract_metadata: Extrair metadados? (padr√£o: True)
    - analyze_video: Analisar v√≠deo com Gemini? (padr√£o: True)
    - process_ai: Processar com Claude? (padr√£o: True)
    - upload_to_cloud: Upload de v√≠deo pra cloud? (padr√£o: False)
    - user_context: Contexto do usu√°rio (opcional, peso 40% na IA)

    **Retorna:**
    - success: True/False
    - bookmark_id: UUID do bookmark
    - estimated_time_seconds: Tempo estimado (60-150s)

    **Vantagens:**
    - ‚úÖ Phone N√ÉO precisa ficar aberto
    - ‚úÖ Simples (sem Redis/Celery)
    - ‚úÖ Processa 2-3 v√≠deos simult√¢neos
    - ‚úÖ Phone sincroniza automaticamente via Realtime
    - ‚úÖ Gr√°tis (sem custo extra)
    """
    try:
        logger.info(f"üöÄ Nova requisi√ß√£o de processamento - Bookmark: {request.bookmark_id}")

        # Valida√ß√µes b√°sicas
        if not request.bookmark_id or not request.url or not request.user_id:
            return ProcessBookmarkCompleteResponse(
                success=False,
                error="bookmark_id, url e user_id s√£o obrigat√≥rios"
            )

        # Atualizar status inicial no Supabase: queued
        try:
            supabase_client.table('bookmarks').update({
                'processing_status': 'queued',
                'error_message': None
            }).eq('id', request.bookmark_id).execute()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao atualizar status inicial (bookmark pode n√£o existir): {str(e)}")
            # N√£o bloqueia - background task vai criar/atualizar depois

        # Adicionar task em background (FastAPI Background Tasks)
        background_tasks.add_task(
            process_bookmark_background,
            bookmark_id=request.bookmark_id,
            url=request.url,
            user_id=request.user_id,
            extract_metadata=request.extract_metadata,
            analyze_video=request.analyze_video,
            process_ai=request.process_ai,
            upload_to_cloud=request.upload_to_cloud,
            user_context=request.user_context
        )

        # Estimar tempo de processamento
        estimated_time = 60  # Base: 60s
        if request.analyze_video:
            estimated_time += 60  # +60s para Gemini
        if request.upload_to_cloud:
            estimated_time += 30  # +30s para upload

        logger.info(f"‚úÖ Background task adicionada - Bookmark: {request.bookmark_id}")

        return ProcessBookmarkCompleteResponse(
            success=True,
            job_id=request.bookmark_id,  # Usa bookmark_id como job_id (n√£o tem job_id separado)
            bookmark_id=request.bookmark_id,
            estimated_time_seconds=estimated_time,
            message=f"Bookmark em processamento. Tempo estimado: {estimated_time}s"
        )

    except Exception as e:
        logger.error(f"‚ùå Erro ao enfileirar job - Bookmark: {request.bookmark_id}, Erro: {str(e)}")
        return ProcessBookmarkCompleteResponse(
            success=False,
            error=f"Erro ao enfileirar processamento: {str(e)}"
        )


@app.on_event("shutdown")
async def shutdown_event():
    await apify_service.close()


if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=os.getenv("ENVIRONMENT") == "development"
    )