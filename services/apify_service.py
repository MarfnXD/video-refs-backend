import os
import json
import asyncio
import redis.asyncio as redis
from typing import List, Optional
from apify_client import ApifyClient
from models import VideoMetadata, Comment, Platform
import httpx
import re
from urllib.parse import urlparse, parse_qs
from services.storage_service import storage_service


class ApifyService:
    def __init__(self):
        # Suporte a mÃºltiplas chaves Apify (2 formatos):
        # Formato 1: APIFY_TOKEN="token1,token2,token3"
        # Formato 2: APIFY_TOKEN, APIFY_TOKEN_2, APIFY_TOKEN_3, etc
        self.apify_tokens = []

        # Tenta formato 1 (comma-separated)
        apify_tokens_str = os.getenv("APIFY_TOKEN", "")
        if ',' in apify_tokens_str:
            self.apify_tokens = [t.strip() for t in apify_tokens_str.split(',') if t.strip()]
        else:
            # Formato 2 (variÃ¡veis separadas)
            if apify_tokens_str:
                self.apify_tokens.append(apify_tokens_str.strip())

            # Procura APIFY_TOKEN_2, APIFY_TOKEN_3, etc
            i = 2
            while True:
                token = os.getenv(f"APIFY_TOKEN_{i}")
                if not token:
                    break
                self.apify_tokens.append(token.strip())
                i += 1

        self.youtube_api_key = os.getenv("YOUTUBE_API_KEY")
        self.redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")

        # Cria clientes para cada token
        self.clients = [ApifyClient(token) for token in self.apify_tokens] if self.apify_tokens else []
        self._current_client_index = 0

        # MantÃ©m compatibilidade com cÃ³digo antigo
        self.apify_token = self.apify_tokens[0] if self.apify_tokens else None
        self.client = self.clients[0] if self.clients else None

        self.redis_client = None

    def _get_next_client(self) -> ApifyClient:
        """Rotaciona entre os clientes Apify (round-robin)"""
        if not self.clients:
            raise ValueError("Nenhum APIFY_TOKEN configurado")

        client = self.clients[self._current_client_index]
        # Print ANTES de incrementar para mostrar o Ã­ndice correto
        print(f"ðŸ”„ Usando Apify token #{self._current_client_index + 1}/{len(self.clients)}")

        self._current_client_index = (self._current_client_index + 1) % len(self.clients)
        return client

    async def _try_all_clients(self, operation_func, operation_name: str = "operaÃ§Ã£o"):
        """
        Tenta executar uma operaÃ§Ã£o com todos os clientes Apify atÃ© conseguir.
        Se um token atingir o limite mensal, tenta automaticamente o prÃ³ximo.

        Args:
            operation_func: FunÃ§Ã£o async que recebe ApifyClient e retorna o resultado
            operation_name: Nome da operaÃ§Ã£o para logs

        Returns:
            Resultado da operaÃ§Ã£o bem-sucedida

        Raises:
            ValueError: Se TODOS os tokens falharem
        """
        if not self.clients:
            raise ValueError("Nenhum APIFY_TOKEN configurado")

        last_error = None
        attempts = len(self.clients)  # Tenta todos os tokens disponÃ­veis

        for attempt in range(attempts):
            try:
                client = self._get_next_client()
                print(f"ðŸ”„ Tentativa {attempt + 1}/{attempts} para {operation_name}")

                result = await operation_func(client)
                print(f"âœ… {operation_name} bem-sucedida com token #{self._current_client_index}/{len(self.clients)}")
                return result

            except Exception as e:
                error_msg = str(e).lower()

                # Detecta erro de limite mensal
                if "monthly usage" in error_msg or "hard limit" in error_msg or "limit exceeded" in error_msg:
                    print(f"âš ï¸ Token #{self._current_client_index}/{len(self.clients)} atingiu limite mensal - tentando prÃ³ximo token...")
                    last_error = e
                    continue

                # Outros erros (nÃ£o relacionados a limite) - falha imediatamente
                print(f"âŒ Erro inesperado em {operation_name}: {str(e)}")
                raise

        # Se chegou aqui, TODOS os tokens falharam
        print(f"âŒ TODOS os {attempts} tokens Apify atingiram limite mensal!")
        raise ValueError(f"Todos os tokens Apify esgotados. Ãšltimo erro: {str(last_error)}")

    async def get_redis_client(self):
        if not self.redis_client:
            self.redis_client = redis.from_url(self.redis_url)
        return self.redis_client

    async def cache_set(self, key: str, value: dict, expire_hours: int = 168):  # 7 dias
        try:
            redis_client = await self.get_redis_client()
            await redis_client.setex(key, expire_hours * 3600, json.dumps(value))
        except Exception:
            pass  # Cache silencioso

    async def cache_get(self, key: str) -> Optional[dict]:
        try:
            redis_client = await self.get_redis_client()
            cached = await redis_client.get(key)
            if cached:
                return json.loads(cached)
        except Exception:
            pass
        return None

    def detect_platform(self, url: str) -> Platform:
        if "youtube.com" in url or "youtu.be" in url:
            return Platform.YOUTUBE
        elif "tiktok.com" in url:
            return Platform.TIKTOK
        elif "instagram.com" in url:
            return Platform.INSTAGRAM
        else:
            raise ValueError(f"Plataforma nÃ£o suportada para URL: {url}")

    def extract_video_id_youtube(self, url: str) -> str:
        if "youtu.be/" in url:
            return url.split("youtu.be/")[-1].split("?")[0]
        elif "youtube.com/watch" in url:
            parsed = urlparse(url)
            return parse_qs(parsed.query)["v"][0]
        else:
            raise ValueError("URL do YouTube invÃ¡lida")

    async def extract_youtube(self, url: str) -> VideoMetadata:
        cache_key = f"youtube:{url}"
        cached = await self.cache_get(cache_key)
        if cached:
            return VideoMetadata(**cached)

        if not self.youtube_api_key:
            raise ValueError("YOUTUBE_API_KEY nÃ£o configurada")

        try:
            video_id = self.extract_video_id_youtube(url)

            async with httpx.AsyncClient() as client:
                # Buscar metadados do vÃ­deo
                video_response = await client.get(
                    "https://www.googleapis.com/youtube/v3/videos",
                    params={
                        "part": "snippet,statistics,contentDetails",
                        "id": video_id,
                        "key": self.youtube_api_key
                    }
                )
                video_data = video_response.json()

                if not video_data["items"]:
                    raise ValueError("VÃ­deo nÃ£o encontrado")

                video_info = video_data["items"][0]
                snippet = video_info["snippet"]
                stats = video_info["statistics"]

                # Buscar comentÃ¡rios
                comments_response = await client.get(
                    "https://www.googleapis.com/youtube/v3/commentThreads",
                    params={
                        "part": "snippet",
                        "videoId": video_id,
                        "maxResults": 50,
                        "order": "relevance",
                        "key": self.youtube_api_key
                    }
                )
                comments_data = comments_response.json()

                top_comments = []
                if "items" in comments_data:
                    # Extrair comentÃ¡rios da resposta
                    comments_list = []
                    for item in comments_data["items"]:
                        comment_snippet = item["snippet"]["topLevelComment"]["snippet"]
                        comments_list.append({
                            "text": comment_snippet["textDisplay"],
                            "author": comment_snippet["authorDisplayName"],
                            "likes": comment_snippet.get("likeCount", 0)
                        })

                    # Ordenar por likes (garantir que os mais relevantes vÃªm primeiro)
                    sorted_comments = sorted(
                        comments_list,
                        key=lambda x: x.get("likes", 0),
                        reverse=True
                    )

                    # Converter para objetos Comment
                    for comment in sorted_comments:
                        top_comments.append(Comment(
                            text=comment["text"],
                            author=comment["author"],
                            likes=comment["likes"]
                        ))

                # Extrair hashtags da descriÃ§Ã£o
                description = snippet.get("description", "")
                hashtags = re.findall(r"#\w+", description)

                metadata = VideoMetadata(
                    url=url,
                    platform=Platform.YOUTUBE,
                    title=snippet["title"],
                    description=description,
                    hashtags=hashtags,
                    views=int(stats.get("viewCount", 0)),
                    likes=int(stats.get("likeCount", 0)),
                    comments_count=int(stats.get("commentCount", 0)),
                    top_comments=top_comments,
                    thumbnail_url=snippet["thumbnails"]["high"]["url"],
                    duration=video_info["contentDetails"]["duration"],
                    author=snippet["channelTitle"],
                    author_url=f"https://www.youtube.com/channel/{snippet['channelId']}",
                    published_at=snippet["publishedAt"]
                )

                await self.cache_set(cache_key, metadata.dict())
                return metadata

        except Exception as e:
            raise ValueError(f"Erro ao extrair metadados do YouTube: {str(e)}")

    async def extract_tiktok(self, url: str) -> VideoMetadata:
        cache_key = f"tiktok:{url}"
        cached = await self.cache_get(cache_key)
        if cached:
            return VideoMetadata(**cached)

        if not self.apify_token:
            raise ValueError("APIFY_TOKEN nÃ£o configurado")

        try:
            run_input = {
                "postUrls": [url],
                "maxItems": 1
            }

            # FunÃ§Ã£o para executar scraping TikTok com um cliente especÃ­fico
            async def run_tiktok_scraper(client: ApifyClient):
                run = client.actor("apify/tiktok-scraper").call(run_input=run_input)
                items = []
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    items.append(item)
                if not items:
                    raise ValueError("VÃ­deo do TikTok nÃ£o encontrado")
                return items[0]

            # Tenta com todos os tokens disponÃ­veis atÃ© conseguir
            data = await self._try_all_clients(run_tiktok_scraper, "extract_tiktok")

            # Extrair comentÃ¡rios se disponÃ­veis (ordenados por likes)
            top_comments = []
            if "comments" in data and data["comments"]:
                # Converter para lista e ordenar por likes (comentÃ¡rios mais relevantes primeiro)
                comments_list = [
                    c for c in data["comments"][:200]
                    if c.get("text")  # SÃ³ comentÃ¡rios com texto
                ]

                # Ordenar por diggCount (likes no TikTok)
                sorted_comments = sorted(
                    comments_list,
                    key=lambda x: x.get("diggCount", 0),
                    reverse=True
                )

                # Pegar top 50 comentÃ¡rios com mais likes
                for comment in sorted_comments[:50]:
                    top_comments.append(Comment(
                        text=comment.get("text", ""),
                        author=comment.get("author", ""),
                        likes=comment.get("diggCount", 0)
                    ))

            # Extrair hashtags
            text = data.get("text", "")
            hashtags = re.findall(r"#\w+", text)

            # Thumbnail temporÃ¡ria do Apify
            temp_thumbnail_url = data.get("imageURL", "")

            # Upload para Supabase Storage (permanente)
            permanent_thumbnail = await storage_service.upload_thumbnail(temp_thumbnail_url, url)
            final_thumbnail_url = permanent_thumbnail if permanent_thumbnail else temp_thumbnail_url

            metadata = VideoMetadata(
                url=url,
                platform=Platform.TIKTOK,
                title=text[:100] + "..." if len(text) > 100 else text,
                description=text,
                hashtags=hashtags,
                views=data.get("playCount", 0),
                likes=data.get("diggCount", 0),
                comments_count=data.get("commentCount", 0),
                top_comments=top_comments,
                thumbnail_url=final_thumbnail_url,
                duration=str(data.get("videoMeta", {}).get("duration", "")),
                author=data.get("authorMeta", {}).get("name", ""),
                author_url=f"https://www.tiktok.com/@{data.get('authorMeta', {}).get('name', '')}",
                published_at=data.get("createTime", "")
            )

            await self.cache_set(cache_key, metadata.dict())
            return metadata

        except Exception as e:
            raise ValueError(f"Erro ao extrair metadados do TikTok: {str(e)}")

    async def extract_instagram_reel(self, url: str) -> VideoMetadata:
        cache_key = f"instagram:{url}"
        cached = await self.cache_get(cache_key)
        if cached:
            return VideoMetadata(**cached)

        if not self.apify_token:
            # Fallback: retorna metadados bÃ¡sicos sem Apify
            return await self._instagram_fallback(url)

        try:
            run_input = {
                "directUrls": [url],
                "resultsType": "posts",
                "resultsLimit": 1,
                "searchType": "hashtag",
                "searchLimit": 1,
                "addParentData": False  # Reduz dados para evitar timeouts
            }

            # FunÃ§Ã£o para executar scraping Instagram com um cliente especÃ­fico
            async def run_instagram_scraper(client: ApifyClient):
                run = client.actor("apify/instagram-scraper").call(
                    run_input=run_input,
                    timeout_secs=120  # 2 minutos max
                )
                items = []
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    items.append(item)
                    break  # Apenas 1 item
                if not items:
                    raise ValueError("Instagram scraper retornou vazio")
                return items[0]

            # Tenta com todos os tokens disponÃ­veis atÃ© conseguir
            data = await self._try_all_clients(run_instagram_scraper, "extract_instagram_reel")

            # ValidaÃ§Ã£o de dados essenciais
            if not data.get("caption") and not data.get("ownerUsername"):
                print("âš ï¸ Instagram scraper retornou dados incompletos - usando fallback")
                return await self._instagram_fallback(url)

            # Extrair comentÃ¡rios se disponÃ­veis (ordenados por likes)
            top_comments = []
            try:
                if "latestComments" in data and data["latestComments"]:
                    # Converter para lista e ordenar por likes (comentÃ¡rios mais relevantes primeiro)
                    comments_list = [
                        c for c in data["latestComments"][:200]
                        if c.get("text")  # SÃ³ comentÃ¡rios com texto
                    ]

                    # Ordenar por likesCount (descendente)
                    sorted_comments = sorted(
                        comments_list,
                        key=lambda x: x.get("likesCount", 0),
                        reverse=True
                    )

                    # Pegar top 50 comentÃ¡rios com mais likes
                    for comment in sorted_comments[:50]:
                        top_comments.append(Comment(
                            text=comment.get("text", ""),
                            author=comment.get("ownerUsername", ""),
                            likes=comment.get("likesCount", 0)
                        ))
            except Exception:
                pass  # Ignora erros em comentÃ¡rios

            # Extrair hashtags da caption
            caption = data.get("caption", "Instagram Reel")
            hashtags = re.findall(r"#\w+", caption)

            # Thumbnail temporÃ¡ria do Apify
            temp_thumbnail_url = data.get("displayUrl", "")

            # Upload para Supabase Storage (permanente) com proteÃ§Ã£o
            final_thumbnail_url = temp_thumbnail_url
            try:
                if temp_thumbnail_url:
                    permanent_thumbnail = await storage_service.upload_thumbnail(temp_thumbnail_url, url)
                    if permanent_thumbnail:
                        final_thumbnail_url = permanent_thumbnail
            except Exception:
                pass  # Usa thumbnail temporÃ¡ria se upload falhar

            metadata = VideoMetadata(
                url=url,
                platform=Platform.INSTAGRAM,
                title=caption[:100] + "..." if len(caption) > 100 else caption if caption else "Instagram Reel",
                description=caption,
                hashtags=hashtags,
                views=data.get("videoViewCount", 0),
                likes=data.get("likesCount", 0),
                comments_count=data.get("commentsCount", 0),
                top_comments=top_comments,
                thumbnail_url=final_thumbnail_url,
                duration=str(data.get("videoDuration", "")) if data.get("videoDuration") else "",
                author=data.get("ownerUsername", "Unknown"),
                author_url=f"https://www.instagram.com/{data.get('ownerUsername', '')}" if data.get('ownerUsername') else "",
                published_at=data.get("timestamp", "")
            )

            await self.cache_set(cache_key, metadata.dict())
            return metadata

        except Exception as e:
            print(f"âŒ Erro no Instagram scraper: {str(e)} - usando fallback")
            return await self._instagram_fallback(url)

    async def _instagram_fallback(self, url: str) -> VideoMetadata:
        """Fallback quando Apify falha - retorna metadados bÃ¡sicos"""
        # Extrai ID do reel/post da URL
        reel_match = re.search(r'/reel/([A-Za-z0-9_-]+)', url)
        post_match = re.search(r'/p/([A-Za-z0-9_-]+)', url)

        post_id = None
        if reel_match:
            post_id = reel_match.group(1)
            title = f"Instagram Reel {post_id[:8]}"
        elif post_match:
            post_id = post_match.group(1)
            title = f"Instagram Post {post_id[:8]}"
        else:
            title = "Instagram Video"

        return VideoMetadata(
            url=url,
            platform=Platform.INSTAGRAM,
            title=title,
            description="",
            hashtags=[],
            views=0,
            likes=0,
            comments_count=0,
            top_comments=[],
            thumbnail_url="",
            duration="",
            author="",
            author_url="",
            published_at=""
        )

    async def extract_metadata(self, url: str) -> VideoMetadata:
        platform = self.detect_platform(url)

        if platform == Platform.YOUTUBE:
            return await self.extract_youtube(url)
        elif platform == Platform.TIKTOK:
            return await self.extract_tiktok(url)
        elif platform == Platform.INSTAGRAM:
            return await self.extract_instagram_reel(url)
        else:
            raise ValueError(f"Plataforma nÃ£o suportada: {platform}")

    async def extract_video_download_url_tiktok(self, url: str, quality: str = "480p") -> dict:
        """
        Extrai URL de download direto do vÃ­deo do TikTok.

        Retorna:
        - download_url: URL direta do vÃ­deo
        - file_size_mb: Tamanho estimado
        - quality: Qualidade real do vÃ­deo
        - expires_in_hours: Validade da URL
        """
        try:
            run_input = {
                "postUrls": [url],
                "maxItems": 1
            }

            # FunÃ§Ã£o para executar scraping TikTok com um cliente especÃ­fico
            async def run_tiktok_downloader(client: ApifyClient):
                run = client.actor("apify/tiktok-scraper").call(run_input=run_input)
                items = []
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    items.append(item)
                if not items:
                    raise ValueError("VÃ­deo do TikTok nÃ£o encontrado")
                return items[0]

            # Tenta com todos os tokens disponÃ­veis atÃ© conseguir
            data = await self._try_all_clients(run_tiktok_downloader, "extract_video_download_url_tiktok")

            # TikTok retorna videoUrl no campo "video"
            video_url = None
            file_size_mb = None

            # Estrutura do TikTok Apify response:
            # - data["video"]["downloadAddr"] = URL de download direto
            # - data["videoMeta"]["width"], data["videoMeta"]["height"] = dimensÃµes
            # - data["videoMeta"]["duration"] = duraÃ§Ã£o em segundos

            if "video" in data:
                video_data = data["video"]
                # URL de download direto (HD se disponÃ­vel)
                video_url = video_data.get("downloadAddr") or video_data.get("playAddr")

                # Tamanho estimado (TikTok nÃ£o sempre retorna, estimamos)
                if "videoMeta" in data:
                    duration = data["videoMeta"].get("duration", 0)
                    # Estimativa: ~1MB por 10 segundos em 480p
                    file_size_mb = round((duration / 10) * 1.0, 2)

            if not video_url:
                raise ValueError("URL de vÃ­deo nÃ£o encontrada no response do TikTok")

            return {
                "download_url": video_url,
                "file_size_mb": file_size_mb,
                "quality": "original",  # TikTok geralmente retorna qualidade original
                "expires_in_hours": 6,  # URLs do TikTok expiram em ~6 horas
            }

        except Exception as e:
            raise ValueError(f"Erro ao extrair URL de download do TikTok: {str(e)}")

    async def extract_video_download_url_instagram(self, url: str, quality: str = "480p") -> dict:
        """
        Extrai URL de download direto do vÃ­deo do Instagram.

        Retorna:
        - download_url: URL direta do vÃ­deo
        - file_size_mb: Tamanho estimado
        - quality: Qualidade real do vÃ­deo
        - expires_in_hours: Validade da URL
        """
        # Tenta Apify primeiro (evita rate-limit do Instagram)
        try:
            run_input = {
                "directUrls": [url],
                "resultsType": "posts",
                "resultsLimit": 1,
                "searchType": "hashtag",
                "searchLimit": 1,
                "addParentData": False
            }

            # FunÃ§Ã£o para executar scraping Instagram com um cliente especÃ­fico
            async def run_instagram_downloader(client: ApifyClient):
                run = client.actor("apify/instagram-scraper").call(
                    run_input=run_input,
                    timeout_secs=120  # 2 minutos max
                )
                items = []
                for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                    items.append(item)
                    break
                if not items:
                    raise ValueError("Instagram scraper retornou vazio")
                data = items[0]
                # Valida se tem videoUrl
                if not data.get("videoUrl"):
                    raise ValueError("Instagram scraper nÃ£o retornou videoUrl")
                return data

            # Tenta com todos os tokens disponÃ­veis atÃ© conseguir
            data = await self._try_all_clients(run_instagram_downloader, "extract_video_download_url_instagram")

            # Instagram retorna videoUrl no campo "videoUrl"
            video_url = data.get("videoUrl")

            # Tamanho estimado
            file_size_mb = None
            if "videoDuration" in data:
                duration = data["videoDuration"]
                # Estimativa: ~1.5MB por 10 segundos em 480p
                file_size_mb = round((duration / 10) * 1.5, 2)

            print("âœ… URL de vÃ­deo Instagram extraÃ­da via Apify")
            return {
                "download_url": video_url,
                "file_size_mb": file_size_mb,
                "quality": "original",  # Instagram retorna qualidade original
                "expires_in_hours": 2,  # URLs do Instagram expiram em ~2 horas
            }

        except Exception as e:
            print(f"âŒ Apify falhou: {str(e)} - tentando yt-dlp")
            return await self._extract_instagram_ytdlp(url, quality)

    async def _extract_instagram_ytdlp(self, url: str, quality: str = "480p") -> dict:
        """Fallback usando yt-dlp para Instagram com formato compatÃ­vel Android"""
        try:
            import subprocess
            import json
            import tempfile

            print(f"ðŸ”§ Tentando yt-dlp para Instagram: {url}")

            # Definir qualidade baseada no parÃ¢metro com MÃšLTIPLOS FALLBACKS
            # Tenta H.264 primeiro, mas aceita qualquer formato se nÃ£o houver
            # Fallback chain: H.264+MP4 â†’ Qualquer MP4 â†’ Qualquer formato com altura limitada â†’ Melhor disponÃ­vel
            quality_map = {
                "low": "worst[ext=mp4][vcodec^=avc1]/worst[ext=mp4]/worst",
                "medium": "best[height<=480][ext=mp4][vcodec^=avc1]/best[height<=480][ext=mp4]/best[height<=480]/best",
                "high": "best[height<=720][ext=mp4][vcodec^=avc1]/best[height<=720][ext=mp4]/best[height<=720]/best"
            }
            format_selector = quality_map.get(quality, "best[height<=480][ext=mp4][vcodec^=avc1]/best[height<=480][ext=mp4]/best[height<=480]/best")

            # Montar comando base
            cmd = [
                "yt-dlp",
                "-j",  # JSON output
                "--no-warnings",
                "--no-check-certificates",
                "--user-agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "-f", format_selector,  # Seleciona formato compatÃ­vel
                "--prefer-free-formats",  # Prefere formatos livres (geralmente mais compatÃ­veis)
            ]

            # Adicionar cookies se configurados
            instagram_cookies = os.getenv("INSTAGRAM_COOKIES")
            cookies_file = None

            if instagram_cookies:
                # Criar arquivo temporÃ¡rio com cookies
                cookies_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
                cookies_file.write(instagram_cookies)
                cookies_file.close()
                cmd.extend(["--cookies", cookies_file.name])
                print("ðŸª Usando cookies do Instagram configurados")

            cmd.append(url)

            # yt-dlp com formato especÃ­fico compatÃ­vel com Android
            # Prioriza H.264 (avc1) em MP4 para mÃ¡xima compatibilidade
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            # Limpar arquivo de cookies temporÃ¡rio
            if cookies_file:
                try:
                    import os as os_module
                    os_module.unlink(cookies_file.name)
                except:
                    pass

            if result.returncode != 0:
                print(f"âš ï¸ yt-dlp stderr: {result.stderr}")
                raise ValueError(f"yt-dlp falhou: {result.stderr}")

            # Limpar output
            stdout_lines = result.stdout.strip().split('\n')
            json_line = None
            for line in stdout_lines:
                if line.startswith('{'):
                    json_line = line
                    break

            if not json_line:
                raise ValueError("yt-dlp nÃ£o retornou JSON vÃ¡lido")

            data = json.loads(json_line)

            # Pegar URL do formato selecionado
            video_url = data.get("url")
            file_size_mb = None

            if "filesize" in data and data["filesize"]:
                file_size_mb = round(data["filesize"] / (1024 * 1024), 2)
            elif "filesize_approx" in data and data["filesize_approx"]:
                file_size_mb = round(data["filesize_approx"] / (1024 * 1024), 2)

            if not video_url:
                raise ValueError("URL de vÃ­deo nÃ£o encontrada no output do yt-dlp")

            print(f"âœ… yt-dlp extraiu URL com sucesso (formato: {data.get('format_id')})")
            return {
                "download_url": video_url,
                "file_size_mb": file_size_mb,
                "quality": quality,
                "expires_in_hours": 2,
            }

        except Exception as e:
            print(f"âŒ yt-dlp falhou completamente: {str(e)}")
            raise ValueError(f"Erro ao extrair URL de download do Instagram (yt-dlp): {str(e)}")

    async def close(self):
        if self.redis_client:
            await self.redis_client.close()