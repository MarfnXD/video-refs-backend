"""
Servi√ßo para processamento de contexto usando Claude 3.5 Sonnet via Replicate
"""
import os
import json
import replicate
from typing import Optional, Dict, List
import logging

logger = logging.getLogger(__name__)

class ClaudeService:
    def __init__(self):
        api_token = os.getenv("REPLICATE_API_TOKEN")
        if not api_token:
            logger.warning("REPLICATE_API_TOKEN n√£o configurada")
            self.client = None
        else:
            self.client = replicate.Client(api_token=api_token)

    async def process_context(
        self,
        user_context_raw: str,
        video_title: str = "",
        platform: str = "",
        author: str = "",
        user_categories: List[str] = None,
        user_projects: List[str] = None
    ) -> Optional[Dict]:
        """
        Processa contexto do usu√°rio com Claude 3.5 Sonnet

        Args:
            user_context_raw: Contexto original do usu√°rio
            video_title: T√≠tulo do v√≠deo
            platform: Plataforma (YouTube, Instagram, TikTok)
            author: Autor/canal do v√≠deo
            user_categories: Categorias existentes do usu√°rio
            user_projects: Projetos existentes do usu√°rio

        Returns:
            Dict com contexto processado, tags, categorias e projetos sugeridos
        """
        if not self.client:
            logger.error("Claude client n√£o inicializado (REPLICATE_API_TOKEN faltando)")
            return None

        if not user_context_raw or not user_context_raw.strip():
            logger.warning("Contexto vazio, pulando processamento")
            return None

        try:
            logger.info(f"üß† Processando contexto com Claude via Replicate...")

            # Preparar listas para o prompt
            categories_list = ", ".join(user_categories) if user_categories else "Nenhuma categoria ainda"
            projects_list = ", ".join(user_projects) if user_projects else "Nenhum projeto ainda"

            # Montar prompt
            prompt = self._build_prompt(
                user_context_raw,
                video_title,
                platform,
                author,
                categories_list,
                projects_list
            )

            # Chamar Claude via Replicate
            # https://replicate.com/anthropic/claude-3.5-sonnet
            output = self.client.run(
                "anthropic/claude-3.5-sonnet",
                input={
                    "prompt": prompt,
                    "max_tokens": 1024,
                    "temperature": 0.3,
                    "top_p": 0.9
                }
            )

            # Extrair resposta (output √© um iterator de strings)
            response_text = ""
            for chunk in output:
                response_text += chunk

            logger.debug(f"Resposta Claude: {response_text}")

            # Parse JSON
            result = json.loads(response_text)

            logger.info(f"‚úÖ Processamento conclu√≠do: {len(result.get('tags', []))} tags, {len(result.get('suggested_categories', []))} categorias")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao parsear JSON da resposta Claude: {str(e)}")
            logger.error(f"Resposta raw: {response_text}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar contexto com Claude: {str(e)}")
            return None

    def _build_prompt(
        self,
        user_context: str,
        video_title: str,
        platform: str,
        author: str,
        categories_list: str,
        projects_list: str
    ) -> str:
        """Constr√≥i o prompt para Claude"""
        return f"""Voc√™ √© um assistente especializado em organizar refer√™ncias criativas para profissionais de v√≠deo/marketing.

CONTEXTO DO USU√ÅRIO:
"{user_context}"

METADADOS DO V√çDEO:
- T√≠tulo: {video_title or "N/A"}
- Plataforma: {platform or "N/A"}
- Canal/Autor: {author or "N/A"}

CATEGORIAS EXISTENTES DO USU√ÅRIO:
{categories_list}

PROJETOS EXISTENTES DO USU√ÅRIO:
{projects_list}

TAREFA:
1. Melhore a nota do usu√°rio (mantenha o sentido, mas torne mais claro e estruturado)
2. Extraia tags relevantes (m√°ximo 5)
3. Sugira M√öLTIPLAS categorias (1-3) dentre as padr√µes ou crie novas:
   PADR√ïES:
   - Ideia de Conte√∫do
   - T√©cnica de Edi√ß√£o
   - Refer√™ncia Visual
   - √Åudio/M√∫sica
   - Mec√¢nica de Campanha
   - Ferramenta/Software
   - Storytelling
   - Outro

   Se o contexto mencionar algo espec√≠fico n√£o coberto, sugira nova categoria.
   Priorize categorias que o usu√°rio j√° usa (se aplic√°vel).

4. Extraia projetos mencionados ou sugira projetos existentes relevantes (m√°ximo 2)
   - Se usu√°rio menciona "para cliente X", "campanha Y", extraia como projeto
   - Se contexto √© similar a projetos existentes, sugira

5. Identifique palavras-chave para busca futura

RETORNE APENAS JSON (sem markdown, sem explica√ß√µes):
{{
  "context_processed": "string (contexto melhorado)",
  "tags": ["tag1", "tag2"],
  "suggested_categories": ["categoria1", "categoria2"],
  "suggested_projects": ["projeto1"],
  "search_keywords": ["keyword1", "keyword2"],
  "confidence": "high|medium|low (qu√£o confiante nas sugest√µes)"
}}"""

    async def process_metadata_auto(
        self,
        title: str,
        description: str = "",
        hashtags: List[str] = None,
        top_comments: List[Dict] = None
    ) -> Optional[Dict]:
        """
        Processa metadados do v√≠deo automaticamente (sem contexto do usu√°rio)

        Args:
            title: T√≠tulo do v√≠deo
            description: Descri√ß√£o do v√≠deo
            hashtags: Lista de hashtags
            top_comments: Lista de coment√°rios top [{text, likes, author}]

        Returns:
            Dict com auto_description, auto_tags, auto_categories
        """
        if not self.client:
            logger.error("Claude client n√£o inicializado (REPLICATE_API_TOKEN faltando)")
            return None

        try:
            logger.info(f"ü§ñ Processando metadados automaticamente com Claude...")

            # Preparar dados
            hashtags_str = ", ".join(hashtags) if hashtags else "Nenhuma"
            comments_str = self._format_comments(top_comments) if top_comments else "Nenhum"

            # Montar prompt
            prompt = self._build_auto_prompt(title, description, hashtags_str, comments_str)

            # Chamar Claude via Replicate
            output = self.client.run(
                "anthropic/claude-3.5-sonnet",
                input={
                    "prompt": prompt,
                    "max_tokens": 1024,
                    "temperature": 0.2,  # Mais determin√≠stico para an√°lise autom√°tica
                    "top_p": 0.9
                }
            )

            # Extrair resposta
            response_text = ""
            for chunk in output:
                response_text += chunk

            logger.debug(f"Resposta Claude (auto): {response_text}")

            # Parse JSON
            result = json.loads(response_text)

            logger.info(f"‚úÖ Processamento autom√°tico conclu√≠do: {len(result.get('auto_tags', []))} tags")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erro ao parsear JSON da resposta Claude (auto): {str(e)}")
            logger.error(f"Resposta raw: {response_text}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar metadados automaticamente: {str(e)}")
            return None

    def _format_comments(self, comments: List[Dict]) -> str:
        """Formata coment√°rios para o prompt"""
        if not comments:
            return "Nenhum"

        formatted = []
        for i, comment in enumerate(comments[:10], 1):  # M√°ximo 10 coment√°rios
            text = comment.get('text', '')
            likes = comment.get('likes', 0)
            formatted.append(f"  {i}. \"{text}\" ({likes} likes)")

        return "\n".join(formatted)

    def _build_auto_prompt(
        self,
        title: str,
        description: str,
        hashtags_str: str,
        comments_str: str
    ) -> str:
        """Constr√≥i o prompt para processamento autom√°tico de metadados"""
        return f"""Voc√™ √© um assistente especializado em analisar v√≠deos de refer√™ncia criativa.

ANALISE OS METADADOS ABAIXO E EXTRAIA INFORMA√á√ïES RELEVANTES:

üìå T√çTULO (peso 40%): "{title}"

üìÑ DESCRI√á√ÉO (peso 30%):
"{description or 'N√£o dispon√≠vel'}"

#Ô∏è‚É£ HASHTAGS (peso 20%):
{hashtags_str}

üí¨ COMENT√ÅRIOS TOP (peso 10%):
{comments_str}

INSTRU√á√ïES DE AN√ÅLISE:
1. **Valida√ß√£o de Consist√™ncia**:
   - Se o t√≠tulo N√ÉO se relaciona com a descri√ß√£o, reduza o peso do t√≠tulo
   - Se t√≠tulo for gen√©rico tipo "üò±", "TRENDING", priorize descri√ß√£o/hashtags

2. **Filtragem de Ru√≠do**:
   - Ignore coment√°rios gen√©ricos: "top", "üî•", "primeiro", "like", etc
   - Priorize coment√°rios que DESCREVEM o conte√∫do

3. **Extra√ß√£o Inteligente**:
   - Identifique o TEMA PRINCIPAL do v√≠deo
   - Extraia T√âCNICAS mencionadas (edi√ß√£o, efeitos, transi√ß√µes, etc)
   - Identifique FERRAMENTAS/SOFTWARE citados
   - Detecte CATEGORIA principal (tutorial, inspira√ß√£o, case, t√©cnica, etc)

4. **Hierarquia de Relev√¢ncia**:
   - T√≠tulo + Descri√ß√£o coerentes = alta confian√ßa
   - S√≥ descri√ß√£o boa = m√©dia confian√ßa
   - S√≥ hashtags/coment√°rios = baixa confian√ßa

CATEGORIAS PADR√ïES (sugira 1-3 mais relevantes):
- T√©cnica de Edi√ß√£o
- Refer√™ncia Visual
- Ideia de Conte√∫do
- √Åudio/M√∫sica
- Ferramenta/Software
- Mec√¢nica de Campanha
- Storytelling
- Tutorial
- Case de Sucesso
- Outro

RETORNE APENAS JSON (sem markdown, sem explica√ß√µes):
{{
  "auto_description": "string (resumo conciso 1-2 frases do QUE √â o v√≠deo)",
  "auto_tags": ["tag1", "tag2", "tag3", "tag4", "tag5"],
  "auto_categories": ["categoria1", "categoria2"],
  "confidence": "high|medium|low",
  "relevance_score": 0.0-1.0 (qu√£o relevante/√∫til √© esse v√≠deo como refer√™ncia)
}}"""

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel"""
        return self.client is not None

# Inst√¢ncia global do servi√ßo
claude_service = ClaudeService()