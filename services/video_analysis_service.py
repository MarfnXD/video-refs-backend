"""
Servi√ßo para an√°lise de conte√∫do de v√≠deo (√°udio + visual)
Usa Whisper API para transcri√ß√£o e GPT-4 Vision para an√°lise visual
Inclui tradu√ß√£o autom√°tica para portugu√™s
"""
import os
import subprocess
import base64
import logging
from typing import Optional, Dict, List
from openai import OpenAI
from pathlib import Path
from services.translation_service import translate_multimodal_analysis

logger = logging.getLogger(__name__)

class VideoAnalysisService:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("OPENAI_API_KEY n√£o configurada")
            self.client = None
        else:
            self.client = OpenAI(api_key=api_key)

    async def analyze_video(self, video_path: str) -> Optional[Dict]:
        """
        Analisa v√≠deo completo: √°udio (transcri√ß√£o) + visual (frames)

        Args:
            video_path: Caminho absoluto do v√≠deo local

        Returns:
            Dict com {
                "transcript": "texto transcrito",
                "language": "pt" ou "en",
                "visual_analysis": "descri√ß√£o visual do conte√∫do"
            }
        """
        if not self.client:
            logger.error("OpenAI client n√£o inicializado")
            return None

        if not os.path.exists(video_path):
            logger.error(f"V√≠deo n√£o encontrado: {video_path}")
            return None

        try:
            logger.info(f"üé¨ Iniciando an√°lise de v√≠deo: {video_path}")

            # 1. Transcrever √°udio
            transcript_data = await self._transcribe_audio(video_path)

            # 2. Analisar frames visualmente
            visual_analysis = await self._analyze_frames(video_path)

            # 3. Traduzir automaticamente para portugu√™s (se necess√°rio)
            transcript = transcript_data.get("text", "") if transcript_data else ""
            language = transcript_data.get("language", "") if transcript_data else ""

            translations = translate_multimodal_analysis(
                video_transcript=transcript,
                visual_analysis=visual_analysis or "",
                transcript_language=language
            )

            result = {
                "transcript": transcript,
                "language": language,
                "visual_analysis": visual_analysis or "",
                # Campos traduzidos (None se j√° estava em PT)
                "transcript_pt": translations.get("video_transcript_pt"),
                "visual_analysis_pt": translations.get("visual_analysis_pt")
            }

            logger.info(f"‚úÖ An√°lise conclu√≠da - Transcript: {len(result['transcript'])} chars, Visual: {len(result['visual_analysis'])} chars")
            if result['transcript_pt']:
                logger.info(f"üåê Tradu√ß√£o PT - Transcript: {len(result['transcript_pt'])} chars")
            if result['visual_analysis_pt']:
                logger.info(f"üåê Tradu√ß√£o PT - Visual: {len(result['visual_analysis_pt'])} chars")
            return result

        except Exception as e:
            logger.error(f"‚ùå Erro ao analisar v√≠deo: {str(e)}")
            return None

    async def _transcribe_audio(self, video_path: str) -> Optional[Dict]:
        """Extrai √°udio e transcreve com Whisper API"""
        try:
            logger.info("üé§ Extraindo e transcrevendo √°udio...")

            # Caminho tempor√°rio para √°udio
            audio_path = video_path.replace(".mp4", "_audio.mp3")

            # Extrair √°udio com FFmpeg (convert to mono, 16kHz para Whisper)
            ffmpeg_cmd = [
                "ffmpeg", "-i", video_path,
                "-vn",  # Sem v√≠deo
                "-ar", "16000",  # Sample rate 16kHz
                "-ac", "1",  # Mono
                "-b:a", "64k",  # Bitrate
                "-y",  # Overwrite
                audio_path
            ]

            result = subprocess.run(
                ffmpeg_cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode != 0:
                logger.error(f"FFmpeg falhou: {result.stderr}")
                return None

            # Verificar tamanho do √°udio
            audio_size = os.path.getsize(audio_path)
            if audio_size > 25 * 1024 * 1024:  # Whisper limit: 25MB
                logger.warning(f"√Åudio muito grande ({audio_size/1024/1024:.1f}MB), pulando transcri√ß√£o")
                os.remove(audio_path)
                return None

            # Transcrever com Whisper
            with open(audio_path, "rb") as audio_file:
                transcript_response = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    response_format="verbose_json"
                )

            # Limpar arquivo tempor√°rio
            os.remove(audio_path)

            transcript_data = {
                "text": transcript_response.text,
                "language": transcript_response.language
            }

            logger.info(f"‚úÖ Transcri√ß√£o conclu√≠da: {len(transcript_data['text'])} chars, idioma: {transcript_data['language']}")
            return transcript_data

        except subprocess.TimeoutExpired:
            logger.error("FFmpeg timeout ao extrair √°udio")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erro ao transcrever √°udio: {str(e)}")
            # Limpar arquivo se existir
            if os.path.exists(audio_path):
                os.remove(audio_path)
            return None

    async def _analyze_frames(self, video_path: str) -> Optional[str]:
        """Extrai frames-chave e analisa com GPT-4 Vision"""
        try:
            logger.info("üñºÔ∏è Extraindo e analisando frames...")

            # Diret√≥rio tempor√°rio para frames
            frames_dir = os.path.join(os.path.dirname(video_path), "temp_frames")
            os.makedirs(frames_dir, exist_ok=True)

            # Extrair 4 frames igualmente espa√ßados (in√≠cio, 1/3, 2/3, fim)
            # fps=1/X significa: capturar 1 frame a cada X segundos
            # select='eq(n,0)+eq(n,floor(N/3))+eq(n,floor(2*N/3))+eq(n,N-1)' = 4 frames

            # Primeiro, pegamos dura√ß√£o do v√≠deo
            duration_cmd = [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                video_path
            ]
            duration_result = subprocess.run(duration_cmd, capture_output=True, text=True, timeout=10)
            duration = float(duration_result.stdout.strip())

            # Extrair 4 frames em tempos espec√≠ficos
            frame_times = [
                0,  # In√≠cio
                duration * 0.33,  # 1/3
                duration * 0.66,  # 2/3
                max(0, duration - 1)  # Final (1s antes do fim)
            ]

            frame_paths = []
            for i, time_sec in enumerate(frame_times):
                frame_path = os.path.join(frames_dir, f"frame_{i}.jpg")
                ffmpeg_cmd = [
                    "ffmpeg", "-ss", str(time_sec),
                    "-i", video_path,
                    "-vframes", "1",
                    "-q:v", "2",  # Alta qualidade
                    "-y",
                    frame_path
                ]
                subprocess.run(ffmpeg_cmd, capture_output=True, timeout=30)

                if os.path.exists(frame_path):
                    frame_paths.append(frame_path)

            if not frame_paths:
                logger.warning("Nenhum frame extra√≠do")
                return None

            # Converter frames para base64
            frame_images = []
            for frame_path in frame_paths:
                with open(frame_path, "rb") as img_file:
                    img_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                    frame_images.append(img_base64)

            # An√°lise com GPT-4 Vision
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """Analyze these 4 frames from a video and describe:

1. Main visual content (what's happening)
2. Detect if it contains:
   - CGI/3D objects in real environments (FOOH advertising)
   - Visual effects (VFX)
   - Augmented reality elements
   - Outdoor advertising/billboards
3. Filming style (animation, live-action, mixed)
4. Notable visual elements

Be concise (2-3 sentences). Focus on TECHNICAL and CREATIVE aspects.
If you detect CGI/FOOH, EXPLICITLY mention it."""
                        }
                    ]
                }
            ]

            # Adicionar as 4 imagens
            for img_base64 in frame_images:
                messages[0]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{img_base64}",
                        "detail": "low"  # Low detail = mais barato
                    }
                })

            # Chamar GPT-4 Vision
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # gpt-4o-mini tem vis√£o e √© mais barato
                messages=messages,
                max_tokens=300,
                temperature=0.3
            )

            visual_analysis = response.choices[0].message.content

            # Limpar frames tempor√°rios
            for frame_path in frame_paths:
                os.remove(frame_path)
            os.rmdir(frames_dir)

            logger.info(f"‚úÖ An√°lise visual conclu√≠da: {len(visual_analysis)} chars")
            return visual_analysis

        except Exception as e:
            logger.error(f"‚ùå Erro ao analisar frames: {str(e)}")
            # Limpar frames se existirem
            if os.path.exists(frames_dir):
                for f in os.listdir(frames_dir):
                    os.remove(os.path.join(frames_dir, f))
                os.rmdir(frames_dir)
            return None

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel"""
        return self.client is not None

# Inst√¢ncia global
video_analysis_service = VideoAnalysisService()
